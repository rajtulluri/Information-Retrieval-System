{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Information Retrieval System</center></h1>\n",
    "<h3><center>Information retrieval system based on ranked retrieval</center></h3>\n",
    "\n",
    "Information retrieval is the activity of obtaining information system resources that are relevant to an information need from a collection of those resources. Searches can be based on full-text or other content-based indexing.<br>\n",
    "\n",
    "The information retrieval system here uses tf-idf scores and cosine similarities to retrieve ranked indices of documents most relevant to the need. The dataset used here is a sample dataset where every document is an image and text associated with it are tags. (The images are not attached here)<br>\n",
    "Upon querying, the query is compared to the tags of every document based on the mentioned scheme and returns ranked (sorted top 10 highest) indices for the images most relevant to the query.<br>\n",
    "\n",
    "The notebook contains step by step code built for the same. The repo contains a compiled script and a short Flask code converting the information system to a server running locally and fulfilling queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hiker, demon, creepy, scary, tunnel, stalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Batman, batman beyond, who are you, narrows it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Up, carl, russell, honor, award, scout badge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tom, jerry, sword, stab, dont care, cartoon, show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Wholesome, comic, dialogue bubble, dog, sleepi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID                                               tags\n",
       "0      0         Hiker, demon, creepy, scary, tunnel, stalk\n",
       "1      1  Batman, batman beyond, who are you, narrows it...\n",
       "2      2  Up, carl, russell, honor, award, scout badge, ...\n",
       "3      3  Tom, jerry, sword, stab, dont care, cartoon, show\n",
       "4      4  Wholesome, comic, dialogue bubble, dog, sleepi..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/hp/Github/Information-Retrieval-System/TagsDatabase.csv',header=None)\n",
    "df.columns = ['docID','tags']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *tags* column is cleaned by the following steps:\n",
    "* Remove punctuations\n",
    "* Lower case\n",
    "* Strip whitespaces\n",
    "* Remove stopwords\n",
    "\n",
    "The docID column has been changed to now represent a document by 'D' followed by the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D0</td>\n",
       "      <td>Hiker, demon, creepy, scary, tunnel, stalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>Batman, batman beyond, who are you, narrows it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>Up, carl, russell, honor, award, scout badge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3</td>\n",
       "      <td>Tom, jerry, sword, stab, dont care, cartoon, show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D4</td>\n",
       "      <td>Wholesome, comic, dialogue bubble, dog, sleepi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docID                                               tags\n",
       "0    D0         Hiker, demon, creepy, scary, tunnel, stalk\n",
       "1    D1  Batman, batman beyond, who are you, narrows it...\n",
       "2    D2  Up, carl, russell, honor, award, scout badge, ...\n",
       "3    D3  Tom, jerry, sword, stab, dont care, cartoon, show\n",
       "4    D4  Wholesome, comic, dialogue bubble, dog, sleepi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.docID = pd.Series([\"D\"+str(ind) for ind in df.docID])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags = df.tags.str.replace(\",\",\" \")\n",
    "df.tags = df.tags.str.replace(r'\\W',' ')\n",
    "df.tags = df.tags.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary (all uniqye words in the documents) are collected into a set as below. This set of vocabulary is  used to match with the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '25',\n",
       " '4',\n",
       " 'alone',\n",
       " 'animated',\n",
       " 'anime',\n",
       " 'announce',\n",
       " 'answer',\n",
       " 'arm',\n",
       " 'award',\n",
       " 'badge',\n",
       " 'batman',\n",
       " 'battle',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'bench',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bismol',\n",
       " 'biting',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'blessing',\n",
       " 'block',\n",
       " 'body',\n",
       " 'bounds',\n",
       " 'brain',\n",
       " 'broom',\n",
       " 'bubble',\n",
       " 'bustling',\n",
       " 'callmecarson',\n",
       " 'cardboard',\n",
       " 'care',\n",
       " 'carl',\n",
       " 'carrying',\n",
       " 'cartoon',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'caught',\n",
       " 'change',\n",
       " 'charlie',\n",
       " 'chef',\n",
       " 'city',\n",
       " 'classic',\n",
       " 'cody',\n",
       " 'college',\n",
       " 'combine',\n",
       " 'comic',\n",
       " 'comparison',\n",
       " 'contradict',\n",
       " 'contradictory',\n",
       " 'creative',\n",
       " 'creepy',\n",
       " 'crossover',\n",
       " 'crusade',\n",
       " 'crying',\n",
       " 'cutout',\n",
       " 'dancing',\n",
       " 'dark',\n",
       " 'dead',\n",
       " 'demon',\n",
       " 'despicable',\n",
       " 'destroy',\n",
       " 'dialogue',\n",
       " 'dimmadome',\n",
       " 'dislike',\n",
       " 'diver',\n",
       " 'dog',\n",
       " 'dont',\n",
       " 'doug',\n",
       " 'dragonballz',\n",
       " 'draw',\n",
       " 'drink',\n",
       " 'employee',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'excuse',\n",
       " 'face',\n",
       " 'fall',\n",
       " 'fallout',\n",
       " 'fast',\n",
       " 'feeding',\n",
       " 'ferb',\n",
       " 'fight',\n",
       " 'fire',\n",
       " 'fit',\n",
       " 'food',\n",
       " 'fool',\n",
       " 'forbidden',\n",
       " 'force',\n",
       " 'fortress',\n",
       " 'freeze',\n",
       " 'frozone',\n",
       " 'funny',\n",
       " 'fusion',\n",
       " 'game',\n",
       " 'gandalf',\n",
       " 'geralt',\n",
       " 'girl',\n",
       " 'god',\n",
       " 'goofy',\n",
       " 'gordon',\n",
       " 'groot',\n",
       " 'growing',\n",
       " 'guard',\n",
       " 'gunpoint',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'hand',\n",
       " 'harry',\n",
       " 'hat',\n",
       " 'hidden',\n",
       " 'hiker',\n",
       " 'holding',\n",
       " 'honor',\n",
       " 'hotdog',\n",
       " 'inc',\n",
       " 'incredibles',\n",
       " 'intelligence',\n",
       " 'jedi',\n",
       " 'jerry',\n",
       " 'jesus',\n",
       " 'johnny',\n",
       " 'joker',\n",
       " 'jump',\n",
       " 'keanu',\n",
       " 'kick',\n",
       " 'kid',\n",
       " 'kids',\n",
       " 'knowledge',\n",
       " 'knows',\n",
       " 'kylo',\n",
       " 'laugh',\n",
       " 'left',\n",
       " 'lesbian',\n",
       " 'life',\n",
       " 'lightsaber',\n",
       " 'long',\n",
       " 'looking',\n",
       " 'lord',\n",
       " 'lotr',\n",
       " 'mabel',\n",
       " 'man',\n",
       " 'many',\n",
       " 'mark',\n",
       " 'master',\n",
       " 'max',\n",
       " 'meet',\n",
       " 'mike',\n",
       " 'mista',\n",
       " 'monster',\n",
       " 'moseby',\n",
       " 'movie',\n",
       " 'mr',\n",
       " 'muscle',\n",
       " 'narrows',\n",
       " 'ninja',\n",
       " 'old',\n",
       " 'option',\n",
       " 'options',\n",
       " 'orton',\n",
       " 'osborn',\n",
       " 'owner',\n",
       " 'panda',\n",
       " 'paper',\n",
       " 'parker',\n",
       " 'patrick',\n",
       " 'peek',\n",
       " 'pepto',\n",
       " 'perry',\n",
       " 'peter',\n",
       " 'phineas',\n",
       " 'phone',\n",
       " 'pipip',\n",
       " 'play',\n",
       " 'pointing',\n",
       " 'police',\n",
       " 'political',\n",
       " 'possessed',\n",
       " 'prefer',\n",
       " 'proud',\n",
       " 'puncher',\n",
       " 'putin',\n",
       " 'pyro',\n",
       " 'ramsay',\n",
       " 'randy',\n",
       " 'reaction',\n",
       " 'reeves',\n",
       " 'regret',\n",
       " 'ren',\n",
       " 'restaurant',\n",
       " 'reveal',\n",
       " 'ride',\n",
       " 'rings',\n",
       " 'russell',\n",
       " 'sad',\n",
       " 'said',\n",
       " 'scaring',\n",
       " 'scary',\n",
       " 'scout',\n",
       " 'sea',\n",
       " 'sending',\n",
       " 'serious',\n",
       " 'shake',\n",
       " 'shock',\n",
       " 'show',\n",
       " 'sign',\n",
       " 'sins',\n",
       " 'slapstick',\n",
       " 'sleeping',\n",
       " 'slide',\n",
       " 'small',\n",
       " 'smiling',\n",
       " 'sofa',\n",
       " 'soos',\n",
       " 'spider',\n",
       " 'split',\n",
       " 'spongebob',\n",
       " 'stab',\n",
       " 'stalk',\n",
       " 'star',\n",
       " 'starwars',\n",
       " 'step',\n",
       " 'stereotype',\n",
       " 'stone',\n",
       " 'stupid',\n",
       " 'support',\n",
       " 'surprise',\n",
       " 'surprised',\n",
       " 'surreal',\n",
       " 'swap',\n",
       " 'sweet',\n",
       " 'swing',\n",
       " 'sword',\n",
       " 'teaching',\n",
       " 'team',\n",
       " 'tear',\n",
       " 'terminator',\n",
       " 'think',\n",
       " 'third',\n",
       " 'time',\n",
       " 'titans',\n",
       " 'tom',\n",
       " 'town',\n",
       " 'toy',\n",
       " 'truth',\n",
       " 'tunnel',\n",
       " 'turtle',\n",
       " 'two',\n",
       " 'undertaker',\n",
       " 'underwater',\n",
       " 'unexpected',\n",
       " 'uno',\n",
       " 'vacuum',\n",
       " 'video',\n",
       " 'videogame',\n",
       " 'voeyer',\n",
       " 'wall',\n",
       " 'wars',\n",
       " 'water',\n",
       " 'wazowski',\n",
       " 'wheel',\n",
       " 'white',\n",
       " 'wholesome',\n",
       " 'wolverine',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'wwe',\n",
       " 'yennefer',\n",
       " 'zach']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = \" \".join(df.tags.values)\n",
    "vocab = np.unique(word_tokenize(all_text))\n",
    "vocab = [word for word in vocab if word not in stopwords.words('english')]\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A term-document-matrix is a mapping of every word in the vocabulary to document. Every document is converted to a vector corresponding to frequency of each word appearing in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_document_matrix(data, vocab= None, document_index= 'ID', text= 'text'):\n",
    "    \"\"\"Calculate frequency of term in the document.\n",
    "    \n",
    "    parameter: \n",
    "        data: DataFrame. \n",
    "        Frequency of word calculated against the data.\n",
    "        \n",
    "        vocab: list of strings.\n",
    "        Vocabulary of the documents    \n",
    "        \n",
    "        document_index: str.\n",
    "        Column name for document index in DataFrame passed.\n",
    "        \n",
    "        text: str\n",
    "        Column name containing text for all documents in DataFrame,\n",
    "        \n",
    "    returns:\n",
    "        vocab_index: DataFrame.\n",
    "        DataFrame containing term document matrix.\n",
    "        \"\"\"\n",
    "    \n",
    "    vocab_index = pd.DataFrame(columns=df[document_index], index= vocab).fillna(0)\n",
    "    \n",
    "    for word in vocab_index.index:\n",
    "        \n",
    "        for doc in data[document_index]:\n",
    "            \n",
    "            freq = data[data[document_index] == doc][text].values[0].count(word)\n",
    "            vocab_index.loc[word,doc] = freq\n",
    "    \n",
    "    return vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>docID</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D44</th>\n",
       "      <th>D45</th>\n",
       "      <th>D46</th>\n",
       "      <th>D47</th>\n",
       "      <th>D48</th>\n",
       "      <th>D49</th>\n",
       "      <th>D50</th>\n",
       "      <th>D51</th>\n",
       "      <th>D52</th>\n",
       "      <th>D53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animated</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wwe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yennefer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "docID     D0  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...  D44  D45  D46  D47  \\\n",
       "2          0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "25         0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4          0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "alone      0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "animated   0   1   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "...       ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "woman      0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "women      0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "wwe        0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "yennefer   0   0   0   0   0   0   0   0   1   0  ...    0    0    0    0   \n",
       "zach       0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "docID     D48  D49  D50  D51  D52  D53  \n",
       "2           0    0    0    0    0    0  \n",
       "25          0    0    0    0    0    0  \n",
       "4           0    0    0    0    0    0  \n",
       "alone       0    0    0    0    0    0  \n",
       "animated    0    0    0    0    0    0  \n",
       "...       ...  ...  ...  ...  ...  ...  \n",
       "woman       0    0    0    0    1    0  \n",
       "women       0    0    0    0    0    1  \n",
       "wwe         0    0    0    0    0    0  \n",
       "yennefer    0    0    0    0    0    0  \n",
       "zach        0    0    0    0    0    0  \n",
       "\n",
       "[272 rows x 54 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_index = term_document_matrix(df,vocab,'docID','tags')\n",
    "similarity_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the term-document-matrix the inverse-document-frequncy is calculated for every document. Using the term-frequencies (tf) and the inverse-document-frequency (idf) the tf-idf score for every word in every document is computed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_score(vocab_index, document_index, inv_df= 'inverse_document_frequency'):\n",
    "    \"\"\"\n",
    "    Calculate tf-idf score for vocabulary in documents\n",
    "    \n",
    "    parameter:\n",
    "        vocab_index: DataFrame.\n",
    "        Term document matrix.\n",
    "        \n",
    "        document_index: list or tuple.\n",
    "        Series containing document ids.\n",
    "        \n",
    "        inv_df: str.\n",
    "        Name of the column with calculated inverse document frequencies.\n",
    "        \n",
    "    returns:\n",
    "        vocab_index: DataFrame.\n",
    "        DataFrame containing term document matrix and document frequencies, inverse document frequencies and tf-idf scores\n",
    "    \"\"\"\n",
    "    total_docx = len(document_index)\n",
    "    vocab_index['document_frequency'] = vocab_index.sum(axis= 1)\n",
    "    vocab_index['inverse_document_frequency'] = np.log2( total_docx / vocab_index['document_frequency'])\n",
    "    \n",
    "    for word in vocab_index.index:\n",
    "        \n",
    "        for doc in document_index:\n",
    "            \n",
    "                tf_idf = np.log2(1 + vocab_index.loc[word,doc]) * np.log2(vocab_index.loc[word][inv_df])\n",
    "                vocab_index.loc[word,'tf_idf_'+doc] = tf_idf\n",
    "    \n",
    "    return vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>docID</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_idf_D44</th>\n",
       "      <th>tf_idf_D45</th>\n",
       "      <th>tf_idf_D46</th>\n",
       "      <th>tf_idf_D47</th>\n",
       "      <th>tf_idf_D48</th>\n",
       "      <th>tf_idf_D49</th>\n",
       "      <th>tf_idf_D50</th>\n",
       "      <th>tf_idf_D51</th>\n",
       "      <th>tf_idf_D52</th>\n",
       "      <th>tf_idf_D53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animated</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.524788</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wwe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yennefer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "docID     D0  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...  tf_idf_D44  tf_idf_D45  \\\n",
       "2          0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "25         0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "4          0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "alone      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "animated   0   1   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "...       ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...         ...         ...   \n",
       "woman      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "women      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "wwe        0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "yennefer   0   0   0   0   0   0   0   0   1   0  ...         0.0         0.0   \n",
       "zach       0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "\n",
       "docID     tf_idf_D46  tf_idf_D47  tf_idf_D48  tf_idf_D49  tf_idf_D50  \\\n",
       "2                0.0         0.0         0.0         0.0         0.0   \n",
       "25               0.0         0.0         0.0         0.0         0.0   \n",
       "4                0.0         0.0         0.0         0.0         0.0   \n",
       "alone            0.0         0.0         0.0         0.0         0.0   \n",
       "animated         0.0         0.0         0.0         0.0         0.0   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "woman            0.0         0.0         0.0         0.0         0.0   \n",
       "women            0.0         0.0         0.0         0.0         0.0   \n",
       "wwe              0.0         0.0         0.0         0.0         0.0   \n",
       "yennefer         0.0         0.0         0.0         0.0         0.0   \n",
       "zach             0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "docID     tf_idf_D51  tf_idf_D52  tf_idf_D53  \n",
       "2                0.0    0.000000    0.000000  \n",
       "25               0.0    0.000000    0.000000  \n",
       "4                0.0    0.000000    0.000000  \n",
       "alone            0.0    0.000000    0.000000  \n",
       "animated         0.0    0.000000    0.000000  \n",
       "...              ...         ...         ...  \n",
       "woman            0.0    2.524788    0.000000  \n",
       "women            0.0    0.000000    2.524788  \n",
       "wwe              0.0    0.000000    0.000000  \n",
       "yennefer         0.0    0.000000    0.000000  \n",
       "zach             0.0    0.000000    0.000000  \n",
       "\n",
       "[272 rows x 110 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_index = tf_idf_score(similarity_index, df.docID.values)\n",
    "similarity_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the above is computation intensive and is only required to do so once unless the database containing documents changes. Thus the above dataframe containing all tf, idfs and the tf-idf scores are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_index.to_csv('term_doc_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= pd.read_csv('term_doc_matrix.csv')\n",
    "test = test.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A huge assumption which is true is that the user will not input the query in a set format. Hence on the same lines as cleaning the tags, the query is also cleaned :\n",
    "* Remove punctutations\n",
    "* Lower case\n",
    "* Remove whitespaces\n",
    "* Remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processing(query):\n",
    "    \"\"\"\n",
    "    Pre-processing query to accomodate calculations for tf-idf score\n",
    "    \n",
    "    parameter:\n",
    "        query: str.\n",
    "        Textual query input to the system.\n",
    "        \n",
    "    returns:\n",
    "        query: str.\n",
    "        Cleaned string.\n",
    "        \"\"\"\n",
    "    query= re.sub('\\W',' ',query)\n",
    "    query= query.strip().lower()\n",
    "    query= \" \".join([word for word in query.split() if word not in stopwords.words('english')])\n",
    "    \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25 batman woman'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"25$ batman' is Woman\"\n",
    "query_processing(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every term in the query, if it exists in the vocabulary, then its tf-idf score is calculated and appended to the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_score(vocab_index, query):\n",
    "    \"\"\"\n",
    "    Calculate tf-idf score for query terms\n",
    "    \n",
    "    parameter:\n",
    "        vocab_index: DataFrame.\n",
    "        Term document matrix with inverse document frequency and term frequencies calculated.\n",
    "        \n",
    "        query: str.\n",
    "        Query submitted to the system\n",
    "        \n",
    "    returns:\n",
    "        vocab_index: DataFrame.\n",
    "        Term document matrix with tf-idf scores for terms per document and query terms.\n",
    "    \"\"\"\n",
    "    for word in np.unique(query.split()):\n",
    "        \n",
    "        freq = query.count(word)\n",
    "        \n",
    "        if word in vocab_index.index:\n",
    "            \n",
    "            tf_idf = np.log2(1+freq) * np.log2(vocab_index.loc[word].inverse_document_frequency)\n",
    "            vocab_index.loc[word,\"query_tf_idf\"] = tf_idf\n",
    "            vocab_index['query_tf_idf'].fillna(0, inplace=True)\n",
    "    \n",
    "    return vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_idf_D45</th>\n",
       "      <th>tf_idf_D46</th>\n",
       "      <th>tf_idf_D47</th>\n",
       "      <th>tf_idf_D48</th>\n",
       "      <th>tf_idf_D49</th>\n",
       "      <th>tf_idf_D50</th>\n",
       "      <th>tf_idf_D51</th>\n",
       "      <th>tf_idf_D52</th>\n",
       "      <th>tf_idf_D53</th>\n",
       "      <th>query_tf_idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animated</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.524788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wwe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yennefer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            D0  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...  tf_idf_D45  \\\n",
       "Unnamed: 0                                          ...               \n",
       "2            0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "25           0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "4            0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "alone        0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "animated     0   1   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "...         ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...         ...   \n",
       "woman        0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "women        0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "wwe          0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "yennefer     0   0   0   0   0   0   0   0   1   0  ...         0.0   \n",
       "zach         0   0   0   0   0   0   0   0   0   0  ...         0.0   \n",
       "\n",
       "            tf_idf_D46  tf_idf_D47  tf_idf_D48  tf_idf_D49  tf_idf_D50  \\\n",
       "Unnamed: 0                                                               \n",
       "2                  0.0         0.0         0.0         0.0         0.0   \n",
       "25                 0.0         0.0         0.0         0.0         0.0   \n",
       "4                  0.0         0.0         0.0         0.0         0.0   \n",
       "alone              0.0         0.0         0.0         0.0         0.0   \n",
       "animated           0.0         0.0         0.0         0.0         0.0   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "woman              0.0         0.0         0.0         0.0         0.0   \n",
       "women              0.0         0.0         0.0         0.0         0.0   \n",
       "wwe                0.0         0.0         0.0         0.0         0.0   \n",
       "yennefer           0.0         0.0         0.0         0.0         0.0   \n",
       "zach               0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "            tf_idf_D51  tf_idf_D52  tf_idf_D53  query_tf_idf  \n",
       "Unnamed: 0                                                    \n",
       "2                  0.0    0.000000    0.000000      0.000000  \n",
       "25                 0.0    0.000000    0.000000      2.524788  \n",
       "4                  0.0    0.000000    0.000000      0.000000  \n",
       "alone              0.0    0.000000    0.000000      2.524788  \n",
       "animated           0.0    0.000000    0.000000      0.000000  \n",
       "...                ...         ...         ...           ...  \n",
       "woman              0.0    2.524788    0.000000      2.524788  \n",
       "women              0.0    0.000000    2.524788      0.000000  \n",
       "wwe                0.0    0.000000    0.000000      0.000000  \n",
       "yennefer           0.0    0.000000    0.000000      0.000000  \n",
       "zach               0.0    0.000000    0.000000      0.000000  \n",
       "\n",
       "[272 rows x 111 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"25 batman alone woman\"\n",
    "similarity_index = query_score(test,query)\n",
    "similarity_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to find the cosine similarities between the query and documents. The cosine similarity determines how similar the two vectors are - Document vector and the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vocab_index, document_index, query_scores):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between the documents and query\n",
    "    \n",
    "    parameter:\n",
    "        \n",
    "        vocab_index: DataFrame.\n",
    "        DataFrame containing tf-idf score per term for every document and for the query terms.\n",
    "        \n",
    "        document_index: list.\n",
    "        List of document ids.\n",
    "        \n",
    "        query_scores: str.\n",
    "        Column name in DataFrame containing query term tf-idf scores.\n",
    "        \n",
    "    returns:\n",
    "        cosine_scores: Series.\n",
    "        Cosine similarity scores of every document.\n",
    "    \"\"\"\n",
    "    cosine_scores = {}\n",
    "    \n",
    "    query_scalar = np.sqrt(sum(vocab_index[query_scores] ** 2))\n",
    "    \n",
    "    for doc in document_index:\n",
    "        \n",
    "        doc_scalar = np.sqrt(sum(vocab_index[doc] ** 2))\n",
    "        dot_prod = sum(vocab_index[doc] * vocab_index[query_scores])\n",
    "        cosine = (dot_prod / (query_scalar * doc_scalar))\n",
    "        \n",
    "        cosine_scores[doc] = cosine\n",
    "        \n",
    "    return pd.Series(cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D0     0.000000\n",
       "D1     0.264088\n",
       "D2     0.000000\n",
       "D3     0.000000\n",
       "D4     0.000000\n",
       "D5     0.000000\n",
       "D6     0.000000\n",
       "D7     0.000000\n",
       "D8     0.000000\n",
       "D9     0.000000\n",
       "D10    0.000000\n",
       "D11    0.000000\n",
       "D12    0.000000\n",
       "D13    0.000000\n",
       "D14    0.000000\n",
       "D15    0.000000\n",
       "D16    0.000000\n",
       "D17    0.000000\n",
       "D18    0.000000\n",
       "D19    0.000000\n",
       "D20    0.000000\n",
       "D21    0.000000\n",
       "D22    0.000000\n",
       "D23    0.000000\n",
       "D24    0.000000\n",
       "D25    0.000000\n",
       "D26    0.000000\n",
       "D27    0.000000\n",
       "D28    0.000000\n",
       "D29    0.000000\n",
       "D30    0.000000\n",
       "D31    0.000000\n",
       "D32    0.000000\n",
       "D33    0.000000\n",
       "D34    0.000000\n",
       "D35    0.000000\n",
       "D36    0.209599\n",
       "D37    0.229604\n",
       "D38    0.000000\n",
       "D39    0.000000\n",
       "D40    0.000000\n",
       "D41    0.000000\n",
       "D42    0.000000\n",
       "D43    0.000000\n",
       "D44    0.000000\n",
       "D45    0.000000\n",
       "D46    0.000000\n",
       "D47    0.000000\n",
       "D48    0.000000\n",
       "D49    0.000000\n",
       "D50    0.000000\n",
       "D51    0.000000\n",
       "D52    0.229604\n",
       "D53    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosines = cosine_similarity(similarity_index, df.docID.values, 'query_tf_idf')\n",
    "cosines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cosine score for every document with the query is calculated. The documents are ranked with respect to their score. The top 'k' documents, here 10, are retrieved in the form of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_index(data,cosine_scores, document_index):\n",
    "    \"\"\"\n",
    "    Retrieves indices for the corresponding document cosine scores\n",
    "    \n",
    "    parameters:\n",
    "        data: DataFrame.\n",
    "        DataFrame containing document ids and text.\n",
    "        \n",
    "        cosine_scores: Series.\n",
    "        Series containing document cosine scores.\n",
    "        \n",
    "        document_index: str.\n",
    "        Column name containing document ids in data.\n",
    "        \n",
    "    returns:\n",
    "        data: DataFrame.\n",
    "        Original DataFrame with cosine scores added as column.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.set_index(document_index)\n",
    "    data['scores'] = cosine_scores\n",
    "    \n",
    "    return data.reset_index().sort_values('scores',ascending=False).head(10).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 52, 37, 36, 0, 39, 29, 30, 31, 32], dtype='int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = retrieve_index(df, cosines, 'docID')\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These indices are the top 10 most relevant images according to the query.<br>\n",
    "The function below, summarizes, by calling, all the above written individual functions. Only the below functions needs to be called to run the system and retrieve indices for a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_system(query):\n",
    "    \"\"\"\n",
    "    Perform a retrieval from the indexes based on the query \n",
    "    and return the document ids that are similar to the query\n",
    "    \n",
    "    paramters:\n",
    "        query: str.\n",
    "        Query submitted to the system.\n",
    "        \n",
    "    returns:\n",
    "        indices: list.\n",
    "        List of document indices which are most relevant to the query.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv('/home/hp/Github/Information-Retrieval-System/TagsDatabase.csv',header=None)\n",
    "\n",
    "    df.columns = ['docID','tags']\n",
    "    df.docID = pd.Series([\"D\"+str(ind) for ind in df.docID])\n",
    "\n",
    "    df.tags = df.tags.str.replace(\",\",\" \")\n",
    "    df.tags = df.tags.str.replace(r'\\W',' ')\n",
    "    df.tags = df.tags.str.strip().str.lower()\n",
    "    \n",
    "    if not path.exists('term_doc_matrix.csv'):    \n",
    "\n",
    "        all_text = \" \".join(df.tags.values)\n",
    "        vocab = np.unique(word_tokenize(all_text))\n",
    "        vocab = [word for word in vocab if word not in stopwords.words('english')]\n",
    "\n",
    "        similarity_index = term_document_matrix(df,vocab,'docID','tags')\n",
    "        similarity_index = tf_idf_score(similarity_index, df.docID.values)\n",
    "        \n",
    "    else:\n",
    "        similarity_index = pd.read_csv('term_doc_matrix.csv')\n",
    "        similarity_index = similarity_index.set_index('Unnamed: 0')\n",
    "        \n",
    "    query = query_processing(query)\n",
    "    similarity_index = query_score(similarity_index,query)\n",
    "    \n",
    "    cosines = cosine_similarity(similarity_index, df.docID.values, 'query_tf_idf')\n",
    "    indices = retrieve_index(df, cosines, 'docID')\n",
    "    \n",
    "    return list(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 36, 3, 16, 40, 30, 31, 32, 33, 34]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_system('25 batman tom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information retrieval system using tf-idf scores and cosine similarities is quite useful and can help in answering information need. The drawback of this method is that it doesnot consider the context of the query (topic) and hence sometimes the results even though relevant with respect to the terms (words) can be off topic.<br>\n",
    "\n",
    "The script for the code is attached in the repo. A small Flask server has been coded (basic) to utilize the information system remotely via GET requests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
