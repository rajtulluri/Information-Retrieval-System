{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hiker, demon, creepy, scary, tunnel, stalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Batman, batman beyond, who are you, narrows it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Up, carl, russell, honor, award, scout badge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tom, jerry, sword, stab, dont care, cartoon, show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Wholesome, comic, dialogue bubble, dog, sleepi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID                                               tags\n",
       "0      0         Hiker, demon, creepy, scary, tunnel, stalk\n",
       "1      1  Batman, batman beyond, who are you, narrows it...\n",
       "2      2  Up, carl, russell, honor, award, scout badge, ...\n",
       "3      3  Tom, jerry, sword, stab, dont care, cartoon, show\n",
       "4      4  Wholesome, comic, dialogue bubble, dog, sleepi..."
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/hp/TagsDatabase.csv',header=None)\n",
    "df.columns = ['docID','tags']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D0</td>\n",
       "      <td>Hiker, demon, creepy, scary, tunnel, stalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>Batman, batman beyond, who are you, narrows it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>Up, carl, russell, honor, award, scout badge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3</td>\n",
       "      <td>Tom, jerry, sword, stab, dont care, cartoon, show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D4</td>\n",
       "      <td>Wholesome, comic, dialogue bubble, dog, sleepi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docID                                               tags\n",
       "0    D0         Hiker, demon, creepy, scary, tunnel, stalk\n",
       "1    D1  Batman, batman beyond, who are you, narrows it...\n",
       "2    D2  Up, carl, russell, honor, award, scout badge, ...\n",
       "3    D3  Tom, jerry, sword, stab, dont care, cartoon, show\n",
       "4    D4  Wholesome, comic, dialogue bubble, dog, sleepi..."
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.docID = pd.Series([\"D\"+str(ind) for ind in df.docID])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags = df.tags.str.replace(\",\",\" \")\n",
    "df.tags = df.tags.str.replace(r'\\W',' ')\n",
    "df.tags = df.tags.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '25',\n",
       " '4',\n",
       " 'alone',\n",
       " 'animated',\n",
       " 'anime',\n",
       " 'announce',\n",
       " 'answer',\n",
       " 'arm',\n",
       " 'award',\n",
       " 'badge',\n",
       " 'batman',\n",
       " 'battle',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'bench',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bismol',\n",
       " 'biting',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'blessing',\n",
       " 'block',\n",
       " 'body',\n",
       " 'bounds',\n",
       " 'brain',\n",
       " 'broom',\n",
       " 'bubble',\n",
       " 'bustling',\n",
       " 'callmecarson',\n",
       " 'cardboard',\n",
       " 'care',\n",
       " 'carl',\n",
       " 'carrying',\n",
       " 'cartoon',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'caught',\n",
       " 'change',\n",
       " 'charlie',\n",
       " 'chef',\n",
       " 'city',\n",
       " 'classic',\n",
       " 'cody',\n",
       " 'college',\n",
       " 'combine',\n",
       " 'comic',\n",
       " 'comparison',\n",
       " 'contradict',\n",
       " 'contradictory',\n",
       " 'creative',\n",
       " 'creepy',\n",
       " 'crossover',\n",
       " 'crusade',\n",
       " 'crying',\n",
       " 'cutout',\n",
       " 'dancing',\n",
       " 'dark',\n",
       " 'dead',\n",
       " 'demon',\n",
       " 'despicable',\n",
       " 'destroy',\n",
       " 'dialogue',\n",
       " 'dimmadome',\n",
       " 'dislike',\n",
       " 'diver',\n",
       " 'dog',\n",
       " 'dont',\n",
       " 'doug',\n",
       " 'dragonballz',\n",
       " 'draw',\n",
       " 'drink',\n",
       " 'employee',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'excuse',\n",
       " 'face',\n",
       " 'fall',\n",
       " 'fallout',\n",
       " 'fast',\n",
       " 'feeding',\n",
       " 'ferb',\n",
       " 'fight',\n",
       " 'fire',\n",
       " 'fit',\n",
       " 'food',\n",
       " 'fool',\n",
       " 'forbidden',\n",
       " 'force',\n",
       " 'fortress',\n",
       " 'freeze',\n",
       " 'frozone',\n",
       " 'funny',\n",
       " 'fusion',\n",
       " 'game',\n",
       " 'gandalf',\n",
       " 'geralt',\n",
       " 'girl',\n",
       " 'god',\n",
       " 'goofy',\n",
       " 'gordon',\n",
       " 'groot',\n",
       " 'growing',\n",
       " 'guard',\n",
       " 'gunpoint',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'hand',\n",
       " 'harry',\n",
       " 'hat',\n",
       " 'hidden',\n",
       " 'hiker',\n",
       " 'holding',\n",
       " 'honor',\n",
       " 'hotdog',\n",
       " 'inc',\n",
       " 'incredibles',\n",
       " 'intelligence',\n",
       " 'jedi',\n",
       " 'jerry',\n",
       " 'jesus',\n",
       " 'johnny',\n",
       " 'joker',\n",
       " 'jump',\n",
       " 'keanu',\n",
       " 'kick',\n",
       " 'kid',\n",
       " 'kids',\n",
       " 'knowledge',\n",
       " 'knows',\n",
       " 'kylo',\n",
       " 'laugh',\n",
       " 'left',\n",
       " 'lesbian',\n",
       " 'life',\n",
       " 'lightsaber',\n",
       " 'long',\n",
       " 'looking',\n",
       " 'lord',\n",
       " 'lotr',\n",
       " 'mabel',\n",
       " 'man',\n",
       " 'many',\n",
       " 'mark',\n",
       " 'master',\n",
       " 'max',\n",
       " 'meet',\n",
       " 'mike',\n",
       " 'mista',\n",
       " 'monster',\n",
       " 'moseby',\n",
       " 'movie',\n",
       " 'mr',\n",
       " 'muscle',\n",
       " 'narrows',\n",
       " 'ninja',\n",
       " 'old',\n",
       " 'option',\n",
       " 'options',\n",
       " 'orton',\n",
       " 'osborn',\n",
       " 'owner',\n",
       " 'panda',\n",
       " 'paper',\n",
       " 'parker',\n",
       " 'patrick',\n",
       " 'peek',\n",
       " 'pepto',\n",
       " 'perry',\n",
       " 'peter',\n",
       " 'phineas',\n",
       " 'phone',\n",
       " 'pipip',\n",
       " 'play',\n",
       " 'pointing',\n",
       " 'police',\n",
       " 'political',\n",
       " 'possessed',\n",
       " 'prefer',\n",
       " 'proud',\n",
       " 'puncher',\n",
       " 'putin',\n",
       " 'pyro',\n",
       " 'ramsay',\n",
       " 'randy',\n",
       " 'reaction',\n",
       " 'reeves',\n",
       " 'regret',\n",
       " 'ren',\n",
       " 'restaurant',\n",
       " 'reveal',\n",
       " 'ride',\n",
       " 'rings',\n",
       " 'russell',\n",
       " 'sad',\n",
       " 'said',\n",
       " 'scaring',\n",
       " 'scary',\n",
       " 'scout',\n",
       " 'sea',\n",
       " 'sending',\n",
       " 'serious',\n",
       " 'shake',\n",
       " 'shock',\n",
       " 'show',\n",
       " 'sign',\n",
       " 'sins',\n",
       " 'slapstick',\n",
       " 'sleeping',\n",
       " 'slide',\n",
       " 'small',\n",
       " 'smiling',\n",
       " 'sofa',\n",
       " 'soos',\n",
       " 'spider',\n",
       " 'split',\n",
       " 'spongebob',\n",
       " 'stab',\n",
       " 'stalk',\n",
       " 'star',\n",
       " 'starwars',\n",
       " 'step',\n",
       " 'stereotype',\n",
       " 'stone',\n",
       " 'stupid',\n",
       " 'support',\n",
       " 'surprise',\n",
       " 'surprised',\n",
       " 'surreal',\n",
       " 'swap',\n",
       " 'sweet',\n",
       " 'swing',\n",
       " 'sword',\n",
       " 'teaching',\n",
       " 'team',\n",
       " 'tear',\n",
       " 'terminator',\n",
       " 'think',\n",
       " 'third',\n",
       " 'time',\n",
       " 'titans',\n",
       " 'tom',\n",
       " 'town',\n",
       " 'toy',\n",
       " 'truth',\n",
       " 'tunnel',\n",
       " 'turtle',\n",
       " 'two',\n",
       " 'undertaker',\n",
       " 'underwater',\n",
       " 'unexpected',\n",
       " 'uno',\n",
       " 'vacuum',\n",
       " 'video',\n",
       " 'videogame',\n",
       " 'voeyer',\n",
       " 'wall',\n",
       " 'wars',\n",
       " 'water',\n",
       " 'wazowski',\n",
       " 'wheel',\n",
       " 'white',\n",
       " 'wholesome',\n",
       " 'wolverine',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'wwe',\n",
       " 'yennefer',\n",
       " 'zach']"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = \" \".join(df.tags.values)\n",
    "vocab = np.unique(word_tokenize(all_text))\n",
    "vocab = [word for word in vocab if word not in stopwords.words('english')]\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_document_matrix(data, vocab= None, document_index= 'ID', text= 'text'):\n",
    "    \"\"\"Calculate frequency of term in the document.\n",
    "    \n",
    "    parameter: \n",
    "        data: DataFrame. \n",
    "        Frequency of word calculated against the data.\n",
    "        \n",
    "        vocab: list of strings.\n",
    "        Vocabulary of the documents    \n",
    "        \n",
    "        document_index: str.\n",
    "        Column name for document index in DataFrame passed.\n",
    "        \n",
    "        text: str\n",
    "        Column name containing text for all documents in DataFrame,\n",
    "        \n",
    "    returns:\n",
    "        vocab_index: DataFrame.\n",
    "        DataFrame containing term document matrix.\n",
    "        \"\"\"\n",
    "    \n",
    "    vocab_index = pd.DataFrame(columns=df[document_index], index= vocab).fillna(0)\n",
    "    \n",
    "    for word in vocab_index.index:\n",
    "        \n",
    "        for doc in data[document_index]:\n",
    "            \n",
    "            freq = data[data[document_index] == doc][text].values[0].count(word)\n",
    "            vocab_index.loc[word,doc] = freq\n",
    "    \n",
    "    return vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>docID</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D44</th>\n",
       "      <th>D45</th>\n",
       "      <th>D46</th>\n",
       "      <th>D47</th>\n",
       "      <th>D48</th>\n",
       "      <th>D49</th>\n",
       "      <th>D50</th>\n",
       "      <th>D51</th>\n",
       "      <th>D52</th>\n",
       "      <th>D53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animated</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wwe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yennefer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "docID     D0  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...  D44  D45  D46  D47  \\\n",
       "2          0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "25         0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4          0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "alone      0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "animated   0   1   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "...       ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "woman      0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "women      0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "wwe        0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "yennefer   0   0   0   0   0   0   0   0   1   0  ...    0    0    0    0   \n",
       "zach       0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "docID     D48  D49  D50  D51  D52  D53  \n",
       "2           0    0    0    0    0    0  \n",
       "25          0    0    0    0    0    0  \n",
       "4           0    0    0    0    0    0  \n",
       "alone       0    0    0    0    0    0  \n",
       "animated    0    0    0    0    0    0  \n",
       "...       ...  ...  ...  ...  ...  ...  \n",
       "woman       0    0    0    0    1    0  \n",
       "women       0    0    0    0    0    1  \n",
       "wwe         0    0    0    0    0    0  \n",
       "yennefer    0    0    0    0    0    0  \n",
       "zach        0    0    0    0    0    0  \n",
       "\n",
       "[272 rows x 54 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_index = term_document_matrix(df,vocab,'docID','tags')\n",
    "similarity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_score(vocab_index, document_index, inv_df= 'inverse_document_frequency'):\n",
    "    \"\"\"\n",
    "    Calculate tf-idf score for vocabulary in documents\n",
    "    \n",
    "    parameter:\n",
    "        vocab_index: DataFrame.\n",
    "        Term document matrix.\n",
    "        \n",
    "        document_index: list or tuple.\n",
    "        Series containing document ids.\n",
    "        \n",
    "        inv_df: str.\n",
    "        Name of the column with calculated inverse document frequencies.\n",
    "        \n",
    "    returns:\n",
    "        vocab_index: DataFrame.\n",
    "        DataFrame containing term document matrix and document frequencies, inverse document frequencies and tf-idf scores\n",
    "    \"\"\"\n",
    "    total_docx = len(document_index)\n",
    "    vocab_index['document_frequency'] = vocab_index.sum(axis= 1)\n",
    "    vocab_index['inverse_document_frequency'] = np.log2( total_docx / vocab_index['document_frequency'])\n",
    "    \n",
    "    for word in vocab_index.index:\n",
    "        \n",
    "        for doc in document_index:\n",
    "            \n",
    "                tf_idf = np.log2(1 + vocab_index.loc[word,doc]) * np.log2(vocab_index.loc[word][inv_df])\n",
    "                vocab_index.loc[word,'tf_idf_'+doc] = tf_idf\n",
    "    \n",
    "    return vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>docID</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_idf_D44</th>\n",
       "      <th>tf_idf_D45</th>\n",
       "      <th>tf_idf_D46</th>\n",
       "      <th>tf_idf_D47</th>\n",
       "      <th>tf_idf_D48</th>\n",
       "      <th>tf_idf_D49</th>\n",
       "      <th>tf_idf_D50</th>\n",
       "      <th>tf_idf_D51</th>\n",
       "      <th>tf_idf_D52</th>\n",
       "      <th>tf_idf_D53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animated</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.524788</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wwe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yennefer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "docID     D0  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...  tf_idf_D44  tf_idf_D45  \\\n",
       "2          0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "25         0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "4          0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "alone      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "animated   0   1   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "...       ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...         ...         ...   \n",
       "woman      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "women      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "wwe        0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "yennefer   0   0   0   0   0   0   0   0   1   0  ...         0.0         0.0   \n",
       "zach       0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "\n",
       "docID     tf_idf_D46  tf_idf_D47  tf_idf_D48  tf_idf_D49  tf_idf_D50  \\\n",
       "2                0.0         0.0         0.0         0.0         0.0   \n",
       "25               0.0         0.0         0.0         0.0         0.0   \n",
       "4                0.0         0.0         0.0         0.0         0.0   \n",
       "alone            0.0         0.0         0.0         0.0         0.0   \n",
       "animated         0.0         0.0         0.0         0.0         0.0   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "woman            0.0         0.0         0.0         0.0         0.0   \n",
       "women            0.0         0.0         0.0         0.0         0.0   \n",
       "wwe              0.0         0.0         0.0         0.0         0.0   \n",
       "yennefer         0.0         0.0         0.0         0.0         0.0   \n",
       "zach             0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "docID     tf_idf_D51  tf_idf_D52  tf_idf_D53  \n",
       "2                0.0    0.000000    0.000000  \n",
       "25               0.0    0.000000    0.000000  \n",
       "4                0.0    0.000000    0.000000  \n",
       "alone            0.0    0.000000    0.000000  \n",
       "animated         0.0    0.000000    0.000000  \n",
       "...              ...         ...         ...  \n",
       "woman            0.0    2.524788    0.000000  \n",
       "women            0.0    0.000000    2.524788  \n",
       "wwe              0.0    0.000000    0.000000  \n",
       "yennefer         0.0    0.000000    0.000000  \n",
       "zach             0.0    0.000000    0.000000  \n",
       "\n",
       "[272 rows x 110 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_index = tf_idf_score(similarity_index, df.docID.values)\n",
    "similarity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processing(query):\n",
    "    \"\"\"\n",
    "    Pre-processing query to accomodate calculations for tf-idf score\n",
    "    \n",
    "    parameter:\n",
    "        query: str.\n",
    "        Textual query input to the system.\n",
    "        \n",
    "    returns:\n",
    "        query: str.\n",
    "        Cleaned string.\n",
    "        \"\"\"\n",
    "    query= re.sub('\\W',' ',query)\n",
    "    query= query.strip().lower()\n",
    "    query= \" \".join([word for word in query.split() if word not in stopwords.words('english')])\n",
    "    \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25 batman woman'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"25$ batman' is Woman\"\n",
    "query_processing(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_score(vocab_index, query):\n",
    "    \"\"\"\n",
    "    Calculate tf-idf score for query terms\n",
    "    \n",
    "    parameter:\n",
    "        vocab_index: DataFrame.\n",
    "        Term document matrix with inverse document frequency and term frequencies calculated.\n",
    "        \n",
    "        query: str.\n",
    "        Query submitted to the system\n",
    "        \n",
    "    returns:\n",
    "        vocab_index: DataFrame.\n",
    "        Term document matrix with tf-idf scores for terms per document and query terms.\n",
    "    \"\"\"\n",
    "    \n",
    "    for word in np.unique(query.split()):\n",
    "        \n",
    "        freq = query.count(word)\n",
    "        \n",
    "        if word in vocab_index.index:\n",
    "            \n",
    "            tf_idf = np.log2(1+freq) * np.log2(vocab_index.loc[word].inverse_document_frequency)\n",
    "            vocab_index.loc[word,\"query_tf_idf\"] = tf_idf\n",
    "            vocab_index['query_tf_idf'].fillna(0, inplace=True)\n",
    "                \n",
    "    return vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>docID</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_idf_D45</th>\n",
       "      <th>tf_idf_D46</th>\n",
       "      <th>tf_idf_D47</th>\n",
       "      <th>tf_idf_D48</th>\n",
       "      <th>tf_idf_D49</th>\n",
       "      <th>tf_idf_D50</th>\n",
       "      <th>tf_idf_D51</th>\n",
       "      <th>tf_idf_D52</th>\n",
       "      <th>tf_idf_D53</th>\n",
       "      <th>query_tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animated</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.524788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524788</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wwe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yennefer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "docID     D0  D1  D2  D3  D4  D5  D6  D7  D8  D9  ...  tf_idf_D45  tf_idf_D46  \\\n",
       "2          0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "25         0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "4          0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "alone      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "animated   0   1   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "...       ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...         ...         ...   \n",
       "woman      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "women      0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "wwe        0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "yennefer   0   0   0   0   0   0   0   0   1   0  ...         0.0         0.0   \n",
       "zach       0   0   0   0   0   0   0   0   0   0  ...         0.0         0.0   \n",
       "\n",
       "docID     tf_idf_D47  tf_idf_D48  tf_idf_D49  tf_idf_D50  tf_idf_D51  \\\n",
       "2                0.0         0.0         0.0         0.0         0.0   \n",
       "25               0.0         0.0         0.0         0.0         0.0   \n",
       "4                0.0         0.0         0.0         0.0         0.0   \n",
       "alone            0.0         0.0         0.0         0.0         0.0   \n",
       "animated         0.0         0.0         0.0         0.0         0.0   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "woman            0.0         0.0         0.0         0.0         0.0   \n",
       "women            0.0         0.0         0.0         0.0         0.0   \n",
       "wwe              0.0         0.0         0.0         0.0         0.0   \n",
       "yennefer         0.0         0.0         0.0         0.0         0.0   \n",
       "zach             0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "docID     tf_idf_D52  tf_idf_D53  query_tf_idf  \n",
       "2           0.000000    0.000000      0.000000  \n",
       "25          0.000000    0.000000      2.524788  \n",
       "4           0.000000    0.000000      0.000000  \n",
       "alone       0.000000    0.000000      2.524788  \n",
       "animated    0.000000    0.000000      0.000000  \n",
       "...              ...         ...           ...  \n",
       "woman       2.524788    0.000000      2.524788  \n",
       "women       0.000000    2.524788      0.000000  \n",
       "wwe         0.000000    0.000000      0.000000  \n",
       "yennefer    0.000000    0.000000      0.000000  \n",
       "zach        0.000000    0.000000      0.000000  \n",
       "\n",
       "[272 rows x 111 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query= \"25 batman alone woman\"\n",
    "similarity_index = query_score(similarity_index,query)\n",
    "similarity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vocab_index, document_index, query_scores):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between the documents and query\n",
    "    \n",
    "    parameter:\n",
    "        \n",
    "        vocab_index: DataFrame.\n",
    "        DataFrame containing tf-idf score per term for every document and for the query terms.\n",
    "        \n",
    "        document_index: list.\n",
    "        List of document ids.\n",
    "        \n",
    "        query_scores: str.\n",
    "        Column name in DataFrame containing query term tf-idf scores.\n",
    "        \n",
    "    returns:\n",
    "        cosine_scores: Series.\n",
    "        Cosine similarity scores of every document.\n",
    "    \"\"\"\n",
    "    cosine_scores = {}\n",
    "    \n",
    "    query_scalar = np.sqrt(sum(vocab_index[query_scores] ** 2))\n",
    "    \n",
    "    for doc in document_index:\n",
    "        \n",
    "        doc_scalar = np.sqrt(sum(vocab_index[doc] ** 2))\n",
    "        dot_prod = sum(vocab_index[doc] * vocab_index[query_scores])\n",
    "        cosine = (dot_prod / (query_scalar * doc_scalar))\n",
    "        \n",
    "        cosine_scores[doc] = cosine\n",
    "        \n",
    "    return pd.Series(cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D0     0.000000\n",
       "D1     0.264088\n",
       "D2     0.000000\n",
       "D3     0.000000\n",
       "D4     0.000000\n",
       "D5     0.000000\n",
       "D6     0.000000\n",
       "D7     0.000000\n",
       "D8     0.000000\n",
       "D9     0.000000\n",
       "D10    0.000000\n",
       "D11    0.000000\n",
       "D12    0.000000\n",
       "D13    0.000000\n",
       "D14    0.000000\n",
       "D15    0.000000\n",
       "D16    0.000000\n",
       "D17    0.000000\n",
       "D18    0.000000\n",
       "D19    0.000000\n",
       "D20    0.000000\n",
       "D21    0.000000\n",
       "D22    0.000000\n",
       "D23    0.000000\n",
       "D24    0.000000\n",
       "D25    0.000000\n",
       "D26    0.000000\n",
       "D27    0.000000\n",
       "D28    0.000000\n",
       "D29    0.000000\n",
       "D30    0.000000\n",
       "D31    0.000000\n",
       "D32    0.000000\n",
       "D33    0.000000\n",
       "D34    0.000000\n",
       "D35    0.000000\n",
       "D36    0.209599\n",
       "D37    0.229604\n",
       "D38    0.000000\n",
       "D39    0.000000\n",
       "D40    0.000000\n",
       "D41    0.000000\n",
       "D42    0.000000\n",
       "D43    0.000000\n",
       "D44    0.000000\n",
       "D45    0.000000\n",
       "D46    0.000000\n",
       "D47    0.000000\n",
       "D48    0.000000\n",
       "D49    0.000000\n",
       "D50    0.000000\n",
       "D51    0.000000\n",
       "D52    0.229604\n",
       "D53    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosines = cosine_similarity(similarity_index, df.docID.values, 'query_tf_idf')\n",
    "cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_index(data,cosine_scores, document_index):\n",
    "    \"\"\"\n",
    "    Retrieves indices for the corresponding document cosine scores\n",
    "    \n",
    "    parameters:\n",
    "        data: DataFrame.\n",
    "        DataFrame containing document ids and text.\n",
    "        \n",
    "        cosine_scores: Series.\n",
    "        Series containing document cosine scores.\n",
    "        \n",
    "        document_index: str.\n",
    "        Column name containing document ids in data.\n",
    "        \n",
    "    returns:\n",
    "        data: DataFrame.\n",
    "        Original DataFrame with cosine scores added as column.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.set_index(document_index)\n",
    "    data['scores'] = cosine_scores\n",
    "    \n",
    "    return data.reset_index().sort_values('scores',ascending=False).head(10).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 52, 37, 36, 0, 39, 29, 30, 31, 32], dtype='int64')"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = retrieve_index(df, cosines, 'docID')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_system(query):\n",
    "    \"\"\"\n",
    "    Perform a retrieval from the indexes based on the query \n",
    "    and return the document ids that are similar to the query\n",
    "    \n",
    "    paramters:\n",
    "        query: str.\n",
    "        Query submitted to the system.\n",
    "        \n",
    "    returns:\n",
    "        indices: list.\n",
    "        List of document indices which are most relevant to the query.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv('/home/hp/TagsDatabase.csv',header=None)\n",
    "    df.columns = ['docID','tags']\n",
    "    df.docID = pd.Series([\"D\"+str(ind) for ind in df.docID])\n",
    "    \n",
    "    df.tags = df.tags.str.replace(\",\",\" \")\n",
    "    df.tags = df.tags.str.replace(r'\\W',' ')\n",
    "    df.tags = df.tags.str.strip().str.lower()\n",
    "    \n",
    "    all_text = \" \".join(df.tags.values)\n",
    "    vocab = np.unique(word_tokenize(all_text))\n",
    "    vocab = [word for word in vocab if word not in stopwords.words('english')]\n",
    "    \n",
    "    similarity_index = term_document_matrix(df,vocab,'docID','tags')\n",
    "    similarity_index = tf_idf_score(similarity_index, df.docID.values)\n",
    "    \n",
    "    query = query_processing(query)\n",
    "    similarity_index = query_score(similarity_index,query)\n",
    "    \n",
    "    cosines = cosine_similarity(similarity_index, df.docID.values, 'query_tf_idf')\n",
    "    indices = retrieve_index(df, cosines, 'docID')\n",
    "    \n",
    "    return list(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 52, 37, 36, 0, 39, 29, 30, 31, 32]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_system('25 batman woman alone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
